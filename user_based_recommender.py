import pandas as pd
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.metrics import mean_squared_error
from collections import Counter
import random

random.seed(42)  # ÎšÎ»ÎµÎ¯Î´Ï‰Î¼Î± Î³Î¹Î± Î±Î½Î±Ï€Î±ÏÎ±Î³Ï‰Î³Î¹Î¼ÏŒÏ„Î·Ï„Î± Ï„Ï‰Î½ Î±Ï€Î¿Ï„ÎµÎ»ÎµÏƒÎ¼Î¬Ï„Ï‰Î½

# === 1. Î¦ÏŒÏÏ„Ï‰ÏƒÎ· ÎºÎ±Î¹ Ï†Î¹Î»Ï„ÏÎ¬ÏÎ¹ÏƒÎ¼Î± Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ ===
df = pd.read_csv("video_games_ready_with_dummy.csv")
df = df[df['reviewerID'].notna()]    # Î”Î¹Î±Î³ÏÎ±Ï†Î® ÎµÎ³Î³ÏÎ±Ï†ÏÎ½ Ï‡Ï‰ÏÎ¯Ï‚ userID
df = df[df['asin'].notna()]          # Î”Î¹Î±Î³ÏÎ±Ï†Î® ÎµÎ³Î³ÏÎ±Ï†ÏÎ½ Ï‡Ï‰ÏÎ¯Ï‚ Ï€ÏÎ¿ÏŠÏŒÎ½
df = df[df['overall'].notna()]       # Î”Î¹Î±Î³ÏÎ±Ï†Î® ÎµÎ³Î³ÏÎ±Ï†ÏÎ½ Ï‡Ï‰ÏÎ¯Ï‚ Î²Î±Î¸Î¼Î¿Î»Î¿Î³Î¯Î±

# Î•Ï€Î¹Î»Î¿Î³Î® Ï‡ÏÎ·ÏƒÏ„ÏÎ½ Î¼Îµ Ï„Î¿Ï…Î»Î¬Ï‡Î¹ÏƒÏ„Î¿Î½ 6 Î±Î¾Î¹Î¿Î»Î¿Î³Î®ÏƒÎµÎ¹Ï‚
user_counts = Counter(df['reviewerID'])
active_users = [user for user, count in user_counts.items() if count >= 6]

print(f"Î•Î½Ï„Î¿Ï€Î¯ÏƒÏ„Î·ÎºÎ±Î½ {len(active_users)} ÎµÎ½ÎµÏÎ³Î¿Î¯ Ï‡ÏÎ®ÏƒÏ„ÎµÏ‚ Î¼Îµ â‰¥6 Î±Î¾Î¹Î¿Î»Î¿Î³Î®ÏƒÎµÎ¹Ï‚.")
print("Î Î±ÏÎ¬Î´ÎµÎ¹Î³Î¼Î±:", active_users[:5])

# === 2. Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Ï€Î¯Î½Î±ÎºÎ± Î±Î¾Î¹Î¿Î»Î¿Î³Î®ÏƒÎµÏ‰Î½ (user-item matrix) ===
ratings_matrix = df.pivot_table(index='reviewerID', columns='asin', values='overall').fillna(0)

# === 3. Î¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚ cosine similarity Î¼ÎµÏ„Î±Î¾Ï Ï‡ÏÎ·ÏƒÏ„ÏÎ½ ===
user_similarity = cosine_similarity(ratings_matrix)
user_similarity_df = pd.DataFrame(user_similarity, index=ratings_matrix.index, columns=ratings_matrix.index)

# === 4. Î•Ï€Î¹Î»Î¿Î³Î® Ï‡ÏÎ·ÏƒÏ„ÏÎ½ Î¼Îµ Ï„Î¿Ï…Î»Î¬Ï‡Î¹ÏƒÏ„Î¿Î½ 2 Î±Î¾Î¹Î¿Î»Î¿Î³Î®ÏƒÎµÎ¹Ï‚ (Î³Î¹Î± RMSE/Precision) ===
active_users = ratings_matrix[ratings_matrix.gt(0).sum(axis=1) >= 2].index.tolist()
print(f"ğŸ§® Î’ÏÎ­Î¸Î·ÎºÎ±Î½ {len(active_users)} ÎµÎ½ÎµÏÎ³Î¿Î¯ Ï‡ÏÎ®ÏƒÏ„ÎµÏ‚ Î¼Îµ â‰¥2 Î±Î¾Î¹Î¿Î»Î¿Î³Î®ÏƒÎµÎ¹Ï‚.")

if not active_users:
    print("âš ï¸ Î”ÎµÎ½ Ï…Ï€Î¬ÏÏ‡Î¿Ï…Î½ Î±ÏÎºÎµÏ„Î¿Î¯ ÎµÎ½ÎµÏÎ³Î¿Î¯ Ï‡ÏÎ®ÏƒÏ„ÎµÏ‚ Î³Î¹Î± Î±Î¾Î¹Î¿Î»ÏŒÎ³Î·ÏƒÎ·.")
    exit()

# === 5. Î£Ï…Î½Î¬ÏÏ„Î·ÏƒÎ· ÏƒÏÏƒÏ„Î±ÏƒÎ·Ï‚ Ï€ÏÎ¿ÏŠÏŒÎ½Ï„Ï‰Î½ Î³Î¹Î± Î­Î½Î±Î½ Ï‡ÏÎ®ÏƒÏ„Î· ===
def recommend_products(user_id, top_n=5):
    if user_id not in user_similarity_df.index:
        return pd.DataFrame()

    # Î•ÏÏÎµÏƒÎ· Ï€Î±ÏÏŒÎ¼Î¿Î¹Ï‰Î½ Ï‡ÏÎ·ÏƒÏ„ÏÎ½ Î¼Îµ Î²Î¬ÏƒÎ· similarity
    sim_users = user_similarity_df[user_id].sort_values(ascending=False)[1:]
    similar_users_ratings = ratings_matrix.loc[sim_users.index]

    # Î£Ï„Î±Î¸Î¼Î¹ÏƒÎ¼Î­Î½Î¿Ï‚ Î¼Î­ÏƒÎ¿Ï‚ ÏŒÏÎ¿Ï‚ Î±Î¾Î¹Î¿Î»Î¿Î³Î®ÏƒÎµÏ‰Î½
    weighted_ratings = similar_users_ratings.T.dot(sim_users)
    recommendation_scores = weighted_ratings / sim_users.sum()

    # Î•ÏÏÎµÏƒÎ· Î¼Î· Î±Î¾Î¹Î¿Î»Î¿Î³Î·Î¼Î­Î½Ï‰Î½ Ï€ÏÎ¿ÏŠÏŒÎ½Ï„Ï‰Î½
    user_rated = ratings_matrix.loc[user_id]
    unrated_items = user_rated[user_rated == 0].index

    # Î•Ï€Î¹Î»Î¿Î³Î® Ï„Ï‰Î½ top Ï€ÏÎ¿Ï„Î¬ÏƒÎµÏ‰Î½
    recommendations = recommendation_scores[unrated_items].sort_values(ascending=False).head(top_n)

    # Î ÏÎ¿ÏƒÎ¸Î®ÎºÎ· Ï„Î¯Ï„Î»Ï‰Î½ Ï€ÏÎ¿ÏŠÏŒÎ½Ï„Ï‰Î½ ÏƒÏ„Î¹Ï‚ Ï€ÏÎ¿Ï„Î¬ÏƒÎµÎ¹Ï‚
    titles = df[['asin', 'title']].dropna().drop_duplicates().set_index('asin')
    results = pd.DataFrame({'asin': recommendations.index, 'score': recommendations.values})
    results['title'] = results['asin'].map(titles['title'])

    return results[['asin', 'title', 'score']]

# === 6. Î•Ï€Î¹Î»Î¿Î³Î® Ï„Ï…Ï‡Î±Î¯Î¿Ï… Ï‡ÏÎ®ÏƒÏ„Î· Î³Î¹Î± Ï€ÏÎ¿Î²Î¿Î»Î® Ï€ÏÎ¿Ï„Î¬ÏƒÎµÏ‰Î½ ===
sample_user = random.choice(active_users)
print(f"Î•Ï€Î¹Î»ÎµÎ³Î¼Î­Î½Î¿Ï‚ Ï‡ÏÎ®ÏƒÏ„Î·Ï‚: {sample_user}")
print(recommend_products(sample_user))

# === 7. Î¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚ RMSE ===
def evaluate_rmse(sample_users, top_n=5):
    actual = []
    predicted = []

    for user in sample_users:
        if user not in ratings_matrix.index:
            continue

        # Î‘Î½Î¬Î»Ï…ÏƒÎ· Î±Î¾Î¹Î¿Î»Î¿Î³Î®ÏƒÎµÏ‰Î½
        user_rated = ratings_matrix.loc[user]
        rated_items = user_rated[user_rated > 0].index.tolist()

        if len(rated_items) < 2:
            continue

        # Î”Î¹Î±Ï‡Ï‰ÏÎ¹ÏƒÎ¼ÏŒÏ‚ ÏƒÎµ train/test (Ï„ÎµÎ»ÎµÏ…Ï„Î±Î¯Î¿ item Î³Î¹Î± test)
        train_items = rated_items[:-1]
        test_item = rated_items[-1]

        temp_matrix = ratings_matrix.copy()
        temp_matrix.loc[user, test_item] = 0  # "ÎºÏÏÎ²Î¿Ï…Î¼Îµ" Ï„Î¿ test item

        sim_users = user_similarity_df[user].sort_values(ascending=False)[1:]
        similar_users_ratings = temp_matrix.loc[sim_users.index]
        weighted_ratings = similar_users_ratings.T.dot(sim_users)
        predicted_rating = weighted_ratings[test_item] / sim_users.sum()

        if not np.isnan(predicted_rating):
            actual.append(ratings_matrix.loc[user, test_item])
            predicted.append(predicted_rating)

    if actual:
        rmse = np.sqrt(mean_squared_error(actual, predicted))
        print(f"RMSE: {rmse:.4f}")
    else:
        print("Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎ±Î½ ÎºÎ±Ï„Î¬Î»Î»Î·Î»Î¿Î¹ Ï‡ÏÎ®ÏƒÏ„ÎµÏ‚ Î³Î¹Î± Î±Î¾Î¹Î¿Î»ÏŒÎ³Î·ÏƒÎ·.")

# === 8. Precision@K ÎºÎ±Î¹ Recall@K ===
def evaluate_precision_recall(sample_users, k=5, min_rating=3):
    precision_list = []
    recall_list = []

    for user in sample_users:
        if user not in ratings_matrix.index:
            continue

        user_rated = ratings_matrix.loc[user]
        rated_items = user_rated[user_rated > 0].index.tolist()

        if len(rated_items) < k + 1:
            continue

        test_item = rated_items[-1]
        train_items = rated_items[:-1]

        temp_matrix = ratings_matrix.copy()
        temp_matrix.loc[user, test_item] = 0

        sim_users = user_similarity_df[user].sort_values(ascending=False)[1:]
        similar_users_ratings = temp_matrix.loc[sim_users.index]
        weighted_ratings = similar_users_ratings.T.dot(sim_users)
        predicted_scores = weighted_ratings / sim_users.sum()

        # Top-k Ï€ÏÎ¿Ï„Î¬ÏƒÎµÎ¹Ï‚
        top_k = predicted_scores.sort_values(ascending=False).head(k).index.tolist()

        # Precision/Recall Î¼Îµ Î²Î¬ÏƒÎ· Ï„Î¿ Î±Î½ Ï€ÎµÏÎ¹Î»Î±Î¼Î²Î¬Î½ÎµÏ„Î±Î¹ Ï„Î¿ test item
        relevant_items = [test_item]
        retrieved_relevant = [item for item in top_k if item in relevant_items]

        precision = len(retrieved_relevant) / k
        recall = len(retrieved_relevant) / len(relevant_items)

        precision_list.append(precision)
        recall_list.append(recall)

    if precision_list:
        avg_precision = np.mean(precision_list)
        avg_recall = np.mean(recall_list)
        print(f"Precision@{k}: {avg_precision:.4f}")
        print(f"Recall@{k}: {avg_recall:.4f}")
    else:
        print("Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎ±Î½ ÎºÎ±Ï„Î¬Î»Î»Î·Î»Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î± Î³Î¹Î± Precision/Recall.")

# === 9. Î•ÎºÏ„Î­Î»ÎµÏƒÎ· Î±Î¾Î¹Î¿Î»ÏŒÎ³Î·ÏƒÎ·Ï‚ ÏƒÎµ Î´ÎµÎ¯Î³Î¼Î± 20 Ï‡ÏÎ·ÏƒÏ„ÏÎ½ ===
sample = random.sample(active_users, min(20, len(active_users)))
evaluate_rmse(sample)
evaluate_precision_recall(sample, k=5)
